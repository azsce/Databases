---
title: "7. chapter 7"
---

#

## More SQL: Complex Queries, Triggers, Views, and Schema Modification

Today, we're diving into **Chapter 7**, which is all about "More SQL." We'll be looking at how to construct **Complex Queries**, understand **Triggers** and **Views**, and finally, how we can go about **Schema Modification**. These are powerful tools that allow for more sophisticated data manipulation and management. So, let's get started.

---
<div class="page-break"></div>

## Chapter 7 Outline

Here's a roadmap for what we'll be covering in this chapter.

*   First, we'll expand on **More Complex SQL Retrieval Queries**. We've learned the basics, but now we'll look at features that allow for much richer data retrieval.
*   Next, we'll discuss **Specifying Semantic Constraints as Assertions and Actions as Triggers**. This is about ensuring data integrity and automating responses to database events.
*   Then, we'll explore **Views**, which are essentially virtual tables in SQL. A very useful concept for simplifying queries and managing access.
*   And finally, we'll cover **Schema Modification in SQL**, which addresses how the database structure itself can be altered after it's been created.

Each of these topics builds upon the last, giving you a more complete picture of SQL's capabilities.

---
<div class="page-break"></div>

## More Complex SQL Retrieval Queries

When we talk about **More Complex SQL Retrieval Queries**, we're referring to a set of additional features that SQL provides. These features empower users to specify much more intricate and sophisticated ways to retrieve data from the database.

As you can see on the slide, this includes:
*   **`Nested queries`**, also known as subqueries, where one query is embedded within another.
*   The use of **`joined tables`** and **`outer joins`** directly within the `FROM` clause, offering more explicit ways to combine data from multiple tables.
*   **`Aggregate functions`**, which allow us to perform calculations across sets of rows, like finding sums or averages.
*   And **`grouping`**, which works hand-in-hand with aggregate functions to summarize data for different categories.

These are the building blocks for asking very detailed and specific questions of our database.

---
<div class="page-break"></div>

## Comparisons Involving NULL and Three-Valued Logic

Now, let's discuss a very important and sometimes tricky concept in SQL: comparisons involving **`NULL`** values and the resulting **`Three-Valued Logic`**.

First, what does `NULL` actually mean? It's not zero, and it's not an empty string. `NULL` represents a few different scenarios:
*   It could be an **Unknown value**: We simply don't know what the value is. For example, the date of birth for a new employee might not have been entered yet.
*   It could be an **Unavailable or withheld value**: The value exists, but we can't access it or it's intentionally not provided.
*   Or, it could signify a **Not applicable attribute**: For instance, a 'spouse_name' attribute would be `NULL` for an unmarried employee because it's not applicable.

A key characteristic is that **each individual `NULL` value is considered to be different from every other `NULL` value**. This has profound implications for comparisons. You can't say `NULL` equals `NULL` and expect a `TRUE` result.

Because of this, SQL employs a **`three-valued logic`** system. Instead of just `TRUE` and `FALSE`, we also have a third logical value: **`UNKNOWN`**. You can think of `UNKNOWN` as a "maybe" or " indeterminate."

And as I just mentioned, a direct comparison like `NULL = NULL` is generally avoided because it would evaluate to `UNKNOWN`, not `TRUE`. We'll see how to properly check for `NULL` shortly. This three-valued logic is fundamental to how SQL handles missing or undefined information.

---
<div class="page-break"></div>

### Comparisons Involving NULL and Three-Valued Logic (cont'd.)

This slide, labeled "Table 7.1 Logical Connectives in Three-Valued Logic," illustrates how our standard logical operators—`AND`, `OR`, and `NOT`—behave in this three-valued system. You don't need to memorize every single cell, but understanding the pattern is crucial.

Let's look at part **(a)**, the **`AND`** operator.
*   If you `AND` `TRUE` with `UNKNOWN`, the result is `UNKNOWN`. Why? Because if that `UNKNOWN` value later turns out to be `FALSE`, the whole expression would be `FALSE`. If it turns out to be `TRUE`, the expression would be `TRUE`. Since we don't know, the result is `UNKNOWN`.
*   However, if you `AND` `FALSE` with `UNKNOWN`, the result is definitively `FALSE`. It doesn't matter what the `UNKNOWN` value is; if one part of an `AND` is `FALSE`, the whole thing is `FALSE`.

Now for part **(b)**, the **`OR`** operator.
*   If you `OR` `TRUE` with `UNKNOWN`, the result is `TRUE`. It doesn't matter what the `UNKNOWN` is; if one part of an `OR` is `TRUE`, the whole expression is `TRUE`.
*   But if you `OR` `FALSE` with `UNKNOWN`, the result is `UNKNOWN`. Similar to the `AND` case, the outcome depends on that unresolved `UNKNOWN`.

Finally, part **(c)** shows the **`NOT`** operator.
*   `NOT TRUE` is `FALSE`, and `NOT FALSE` is `TRUE`, as you'd expect.
*   Interestingly, `NOT UNKNOWN` is still `UNKNOWN`. If we don't know the truth value of something, negating it doesn't suddenly give us a definitive answer.

These rules are applied by the database system whenever conditions in your `WHERE` clauses involve `NULL` values.

---
<div class="page-break"></div>

### Three-Valued Logic

This slide provides another, perhaps more comprehensive, table illustrating this **`Three-Valued Logic`**.

It tabulates the results for combinations of `p` and `q` (which can be `True`, `False`, or `Unknown`) for the operations `p OR q`, `p AND q`, and even `p = q`.

Let's pick an example from the `p = q` column.
*   If `p` is `True` and `q` is `Unknown`, then `p = q` results in `Unknown`. We can't definitively say they are equal or not.
*   And as we've emphasized, if `p` is `Unknown` and `q` is `Unknown`, `p = q` still results in `Unknown`. This is a common point of confusion – two `NULL`s are not considered equal to each other in a standard equality check.

The smaller table at the bottom simply reiterates the `NOT` operator: `NOT True` is `False`, `NOT False` is `True`, and `NOT Unknown` remains `Unknown`.

Understanding these truth tables is key to predicting how your SQL queries will behave, especially when your data contains `NULL`s. It helps in debugging queries where you might not be getting the results you expect.

---
<div class="page-break"></div>

### Comparisons Involving NULL and Three-Valued Logic (cont'd.)

So, if we can't use `column = NULL` to check for `NULL` values, how do we do it?

SQL provides specific predicates for this: **`IS NULL`** and **`IS NOT NULL`**.
*   To check if an attribute's value *is* `NULL`, you use `attribute_name IS NULL`.
*   To check if an attribute's value *is not* `NULL`, you use `attribute_name IS NOT NULL`.

Let's look at **Query 18** on the slide. The goal is to "Retrieve the names of all employees who do not have supervisors." In our typical `EMPLOYEE` table schema, the supervisor information is often stored in a `Super_ssn` (Supervisor's Social Security Number) column. If an employee doesn't have a supervisor (perhaps they are the head of the company), this `Super_ssn` field would likely be `NULL`.

The query is:
`SELECT Fname, Lname FROM EMPLOYEE WHERE Super_ssn IS NULL;`

Here, the `WHERE Super_ssn IS NULL` clause correctly identifies those employees. If we had mistakenly written `WHERE Super_ssn = NULL`, it would evaluate to `UNKNOWN` for every row, and we wouldn't get any results, which is not what we want. So, remember, for `NULL` checking, always use `IS NULL` or `IS NOT NULL`.

---
<div class="page-break"></div>

## Nested Queries, Tuples, and Set/Multiset Comparisons

Alright, let's move on to **`Nested Queries`**, also commonly referred to as subqueries. This is a very powerful feature in SQL.

*   A **`nested query`** is essentially a complete `SELECT-FROM-WHERE` block that is embedded within the `WHERE` clause (or sometimes other clauses) of another query.
*   We typically refer to the main query as the **`outer query`** and the embedded query as the **`nested subquery`** or inner query.

One common way to use nested queries is with the **`IN` comparison operator**.
*   The `IN` operator is used to compare a value `v` with a set (or, more accurately, a multiset, as SQL allows duplicates) of values, let's call it `V`, which is typically generated by the subquery.
*   The expression `v IN V` evaluates to `TRUE` if the value `v` is found among the elements in the set `V`. Otherwise, it's `FALSE` (or `UNKNOWN` if `NULL`s are involved in a complex way, but let's stick to `TRUE`/`FALSE` for the basic understanding).

Nested queries allow us to break down complex problems into smaller, more manageable parts, where the result of one part (the subquery) feeds into the condition of another part (the outer query).

---
<div class="page-break"></div>

### Nested Queries (cont'd.)

Let's look at an example to make this clearer. The task described is: "Make a list of all project numbers for projects that involve employee Smith either as a worker or as a manager of the department that controls the project."

This is a classic scenario where nested queries shine. We need to find project numbers based on two distinct conditions, combined with an `OR`.

Consider query **`Q4A`**:
`SELECT DISTINCT Pnumber FROM PROJECT WHERE Pnumber IN (...) OR Pnumber IN (...);`

The outer query is selecting distinct project numbers (`Pnumber`) from the `PROJECT` table. The `WHERE` clause has two conditions joined by `OR`, and each condition uses the `IN` operator with a subquery.

*   The **first subquery**:
    `(SELECT Pnumber FROM PROJECT, DEPARTMENT, EMPLOYEE WHERE Dnum=Dnumber AND Mgr_ssn=Ssn AND Lname='Smith')`
    This subquery finds project numbers for projects controlled by a department where 'Smith' is the manager. It joins `PROJECT`, `DEPARTMENT`, and `EMPLOYEE` tables and filters for `Lname='Smith'` who is a manager (`Mgr_ssn=Ssn`).

*   The **second subquery**:
    `(SELECT Pno FROM WORKS_ON, EMPLOYEE WHERE Essn=Ssn AND Lname='Smith')`
    This subquery finds project numbers (aliased as `Pno` in `WORKS_ON`) on which an employee named 'Smith' directly works. It joins `WORKS_ON` and `EMPLOYEE` and filters for `Lname='Smith'`.

So, the outer query will return a project number if it's found in the results of *either* of these subqueries. The `DISTINCT` keyword ensures that if a project meets both conditions, it's only listed once in the final result. This demonstrates how subqueries can neatly encapsulate complex conditions.

---
<div class="page-break"></div>

### Nested Queries (cont'd.)

SQL also allows us to use **tuples of values in comparisons**, which can be very convenient.
*   When you want to compare multiple values from a row simultaneously, you can group them within parentheses to form a tuple.

Look at the example query on this slide:
`SELECT DISTINCT Essn FROM WORKS_ON WHERE (Pno, Hours) IN (SELECT Pno, Hours FROM WORKS_ON WHERE Essn='987654321');`
*(Professor's note: I've used a generic placeholder '987654321' for the Employee SSN here for illustrative purposes.)*

Here's what's happening:
The outer query is selecting distinct employee SSNs from the `WORKS_ON` table.
The `WHERE` clause uses a tuple comparison: `(Pno, Hours) IN (...)`. This means we are looking for rows in the outer `WORKS_ON` table where the *combination* of `Pno` (project number) and `Hours` matches a `Pno` and `Hours` combination produced by the subquery.

The subquery:
`(SELECT Pno, Hours FROM WORKS_ON WHERE Essn='987654321')`
This subquery retrieves all pairs of `(Pno, Hours)` for the employee whose `Essn` is '987654321'.

So, effectively, this query finds all employees who work on the *same projects for the same number of hours* as employee '987654321'. This is a concise way to express what would otherwise require a more complex join or multiple conditions. Using tuples in the `IN` clause can make your queries more readable and often more efficient for these kinds of multi-attribute comparisons.

---
<div class="page-break"></div>

### Nested Queries (cont'd.)

Beyond the `IN` operator, SQL provides other comparison operators that can be used with subqueries, particularly when the subquery is guaranteed to return a single column of values.

The slide mentions **`= ANY`** (or its synonym **`= SOME`**) and states that it's equivalent to `IN`.
*   So, `value = ANY (subquery)` (or `value = SOME (subquery)`) will return `TRUE` if the `value` is equal to *at least one* of the values returned by the subquery. This is indeed how `IN` behaves.

But the real power comes when we combine `ANY` or `SOME` with *other* comparison operators like `>`, `>=`, `<`, `<=`, and `<>` (not equal).
*   For example, `value > ANY (subquery)` would be `TRUE` if the `value` is greater than *at least one* of the values returned by the subquery.
*   Think about `value < ANY (subquery)`: `TRUE` if `value` is less than *at least one* value from the subquery.

Then there's the **`ALL`** operator. This one is stricter.
*   `value > ALL (subquery)` means the `value` must be greater than *every single value* returned by the subquery.
*   Similarly, `value = ALL (subquery)` would only be true if the subquery returned exactly one value, and `value` was equal to it (or if the subquery returned multiple identical values, and `value` matched them all).

Let's look at the example given for `ALL`:
`SELECT Lname, Fname FROM EMPLOYEE WHERE Salary > ALL (SELECT Salary FROM EMPLOYEE WHERE Dno=5);`

This query aims to find employees whose salary is greater than *every* salary of *every* employee in department number 5. In other words, it finds employees who earn more than the highest-paid employee in department 5 (excluding the employees in department 5 themselves, unless they are also the highest overall and not in dept 5).
This is a powerful way to compare a value against an entire set of values derived from a subquery, using conditions beyond simple equality.

---
<div class="page-break"></div>

## General Form of ALL, ANY, SOME

This slide provides the general syntax for using `ALL`, `ANY`, or `SOME` with a subquery in the `WHERE` clause.

The structure is:
`SELECT [column_name(s)]`
`FROM [table_name(s)]`
`WHERE expression operator {ALL | ANY | SOME} (subquery)`

Let's break this down:
*   `expression`: This is typically a column from the outer query, or a literal value, whose value is being compared.
*   `operator`: This is one of the standard comparison operators: `=`, `>`, `<`, `>=`, `<=`, or `<>`.
*   `{ALL | ANY | SOME}`: You choose one of these keywords to specify how the comparison should be made against the set of values returned by the subquery.
    *   `ANY` (or `SOME`) means the condition must be true for at least one value returned by the subquery.
    *   `ALL` means the condition must be true for all values returned by the subquery.
*   `(subquery)`: This is your nested `SELECT` statement, which must return a single column of values for these operators to work correctly.

This syntax provides a flexible and powerful mechanism for performing set-based comparisons within your SQL queries.

---
<div class="page-break"></div>

### Nested Queries (cont'd.)

A very important practice when dealing with nested queries, especially *correlated* nested queries (which we'll touch on more formally soon), is to **avoid potential errors and ambiguities by using tuple variables, or aliases, for all tables referenced in the SQL query.**

When a subquery refers to columns from tables that are also used in the outer query, it can sometimes be ambiguous which table instance a column name refers to. Using aliases makes your intentions explicit.

Let's look at **Query 16**: "Retrieve the name of each employee who has a dependent with the same first name and is the same sex as the employee."

The query is structured as:
`SELECT E.Fname, E.Lname FROM EMPLOYEE AS E WHERE E.Ssn IN (SELECT Essn FROM DEPENDENT AS D WHERE E.Fname=D.Dependent_name AND E.Sex=D.Sex);`

Notice the aliases:
*   In the outer query, `EMPLOYEE` is aliased as `E`.
*   In the subquery, `DEPENDENT` is aliased as `D`.

Now look at the subquery's `WHERE` clause: `WHERE E.Fname=D.Dependent_name AND E.Sex=D.Sex`.
Here, `E.Fname` and `E.Sex` clearly refer to the `Fname` and `Sex` of the *current employee record being processed by the outer query*. `D.Dependent_name` refers to the dependent's name from the `DEPENDENT` table (aliased as `D`) in the subquery.

Without these aliases, if both `EMPLOYEE` and `DEPENDENT` tables had, say, a `Fname` column, a simple `Fname = Dependent_name` might be ambiguous or interpreted incorrectly by the DBMS. Aliasing resolves this and makes the query's logic much clearer and less prone to errors. This is a hallmark of good SQL practice, especially as queries grow in complexity.

---
<div class="page-break"></div>

### Understanding a nested (correlated) query

Let's take a closer look at **Query 16** from the previous slide to understand how this type of nested query, specifically a *correlated* nested query, is conceptually evaluated.

The query again: "Retrieve the name of each employee who has a dependent with the same first name and is the same sex as the employee."
`Q16: SELECT E.Fname, E.Lname FROM EMPLOYEE AS E WHERE E.Ssn IN (SELECT Essn FROM DEPENDENT AS D WHERE E.Fname=D.Dependent_name AND E.Sex=D.Sex);`

Here's the crucial part: The subquery `(SELECT Essn FROM DEPENDENT AS D WHERE E.Fname=D.Dependent_name AND E.Sex=D.Sex)` is **correlated** with the outer query. This means that the subquery is not independent; its execution depends on values from the current row being processed by the outer query. Specifically, `E.Fname` and `E.Sex` in the subquery's `WHERE` clause refer to the `Fname` and `Sex` of the employee `E` from the outer query.

So, the evaluation process can be thought of like this:

1.  **For each tuple (row) `E` in the `EMPLOYEE` table (from the outer query):**
    a.  Take the `Fname` and `Sex` values from the current employee tuple `E`.
    b.  **Evaluate the nested subquery *using these specific `E.Fname` and `E.Sex` values***. This subquery will then scan the `DEPENDENT` table (aliased as `D`) and retrieve the `Essn` (which is the employee's SSN linking to their dependents) for all dependents `D` whose `Dependent_name` matches `E.Fname` AND whose `Sex` matches `E.Sex`.
    c.  This subquery execution produces a temporary set of `Essn` values for the *current* employee `E`.
    d.  Then, the outer query's condition `E.Ssn IN (...)` is checked. If the `Ssn` of the current employee `E` is present in the set of `Essn` values returned by the subquery (for this specific `E`), then the condition is `TRUE`.
    e.  If the condition is `TRUE`, then the `E.Fname` and `E.Lname` of the current employee `E` are selected for the final result.

This process repeats for every single employee in the `EMPLOYEE` table. Because the subquery is re-evaluated (at least conceptually) for each row of the outer query, using values from that outer row, it's termed a **`correlated nested query`**. This is a powerful construct, but it's also important to be aware that it can sometimes lead to performance issues if not written carefully or if the tables are very large, precisely because of this repeated evaluation.

---
<div class="page-break"></div>

## Correlated Nested Queries

Building on what we just discussed, let's formally define and look at an alternative for some types of **`Correlated Nested Queries`**.

The slide mentions that queries nested using the `=` or `IN` comparison operator *can often be "collapsed" or rewritten into a single block query using a join*. This is particularly true for many correlated subqueries.

Remember **Query 16**?
`SELECT E.Fname, E.Lname FROM EMPLOYEE AS E WHERE E.Ssn IN (SELECT Essn FROM DEPENDENT AS D WHERE E.Fname=D.Dependent_name AND E.Sex=D.Sex);`

This correlated nested query can indeed be rewritten as a direct join, as shown in **`Q16A`**:
`SELECT E.Fname, E.Lname FROM EMPLOYEE AS E, DEPENDENT AS D WHERE E.Ssn=D.Essn AND E.Sex=D.Sex AND E.Fname=D.Dependent_name;`

In `Q16A`, we're explicitly joining the `EMPLOYEE` table (aliased as `E`) with the `DEPENDENT` table (aliased as `D`).
The `WHERE` clause now contains all the conditions:
*   `E.Ssn=D.Essn`: This is the join condition linking an employee to their dependents.
*   `E.Sex=D.Sex`: This ensures the employee and dependent have the same sex.
*   `E.Fname=D.Dependent_name`: This ensures the employee's first name matches the dependent's name.

Often, database optimizers are smart enough to transform a correlated subquery (like `Q16`) into an equivalent join (like `Q16A`) internally for better performance. However, writing it explicitly as a join can sometimes be clearer or give the optimizer a more direct path.

The key takeaway for a **`correlated nested query`** is that it is **evaluated once for each tuple in the outer query**. This is the defining characteristic and the reason why we need to be mindful of its potential performance implications, especially if the subquery itself is complex or operates on large tables.

---
<div class="page-break"></div>

## The EXISTS and UNIQUE Functions in SQL for correlating queries

SQL provides other ways to work with correlated queries, notably using the **`EXISTS` function**.

*   The **`EXISTS` function** is specifically designed to be used with correlated nested queries.
*   Its purpose is to **check whether the result of a correlated nested subquery is empty or not**.
    *   If the subquery returns *at least one row*, `EXISTS (subquery)` evaluates to `TRUE`.
    *   If the subquery returns *no rows* (an empty set), `EXISTS (subquery)` evaluates to `FALSE`.
*   `EXISTS` is a Boolean function; it returns `TRUE` or `FALSE`. It doesn't care *what* data the subquery returns, only *whether* it returns anything. For this reason, it's common practice to use `SELECT *` or `SELECT 1` within an `EXISTS` subquery, as the actual columns selected don't matter.

We also have **`NOT EXISTS`**, which, as you'd expect, evaluates to `TRUE` if the subquery returns no rows, and `FALSE` if it returns one or more rows.

`EXISTS` and `NOT EXISTS` are almost always used in conjunction with a correlated nested query because the subquery typically depends on values from the outer query to determine if any matching rows exist.

The slide also mentions the SQL function **`UNIQUE (Q)`**.
*   `UNIQUE (Q)` (where `Q` is a subquery) is designed to test if all tuples in the result of subquery `Q` are distinct. It returns `TRUE` if there are no duplicate tuples in the result of query `Q`, and `FALSE` otherwise.
*   While `UNIQUE` is part of the SQL standard, its usage is less common in everyday querying compared to `EXISTS`. `EXISTS` is a very common pattern for certain types of conditional checks.

---
<div class="page-break"></div>

## USE of EXISTS

Let's see an example of how **`EXISTS`** is used. This is a common and quite elegant way to handle certain types of conditional queries.
The task before us is: "List the managers who have at least one dependent."

Now, if you look at query **`Q7`** on the slide, you'll see it's structured to achieve this.
The outer part of the query is straightforward: it's aiming to select the first name (`Fname`) and last name (`Lname`) from our `Employee` table.

The interesting part is the `WHERE` clause. It uses `EXISTS` twice, combined with an `AND` condition. This means for an employee to be selected, *both* `EXISTS` conditions must evaluate to true.

1.  The **first `EXISTS` condition** checks if there's any corresponding record in the `DEPENDENT` table for the current employee.
    *   Inside this `EXISTS`, there's a subquery. This subquery looks into the `DEPENDENT` table. The crucial part is the `WHERE` clause of this subquery, `WHERE Ssn = Essn` (or as I might write for clarity, `WHERE DEPENDENT.Essn = Employee.Ssn`). This links the `Essn` in the `DEPENDENT` table (which identifies the employee to whom the dependent belongs) to the `Ssn` of the employee currently being considered by the outer query.
    *   So, if for the current employee, this subquery finds *at least one* matching row in the `DEPENDENT` table, it means this employee has at least one dependent, and this first `EXISTS` check becomes `TRUE`. The `SELECT *` is just a convention; we could use `SELECT 1` or any literal, as `EXISTS` only cares about the presence or absence of rows, not their content.

2.  The **second `EXISTS` condition**, joined by `AND`, checks if the current employee is a manager.
    *   The subquery here looks into the `Department` table.
    *   Its `WHERE` clause, `WHERE Ssn = Mgr_Ssn` (or more explicitly, `WHERE Department.Mgr_Ssn = Employee.Ssn`), checks if the current employee's `Ssn` appears as a manager's SSN (`Mgr_Ssn`) in any department record.
    *   If this subquery finds *at least one* such department, it means the current employee is indeed a manager, and this second `EXISTS` check becomes `TRUE`.

Therefore, an employee's name will only appear in the final result if they satisfy both conditions: they have at least one dependent, AND they are a manager of a department. `EXISTS` is particularly efficient here because the database can often determine the truth of the `EXISTS` condition as soon as it finds the *first* relevant row in the subquery, without needing to process the entire subquery's potential result set.

---
<div class="page-break"></div>

## Explicit Sets and Renaming of Attributes in SQL

SQL offers a couple of other conveniences that can make queries more direct or results more readable.

First, you **can use an explicit set of values directly in a `WHERE` clause**, typically with the `IN` operator.
*   Instead of having a subquery generate a list of values for the `IN` operator, you can just type out the list of values yourself.

Look at **Query `Q17`** on the slide.
The query aims to get distinct employee SSNs (`Essn`) from the `WORKS_ON` table.
The `WHERE` clause is `WHERE Pno IN (1, 2, 3);`.
This simply means we're interested in employees who work on project number 1, OR project number 2, OR project number 3. It's a very straightforward way to check against a small, fixed list of values.

---

Second, SQL allows you to **rename attributes in the result of a query using the `AS` qualifier**. This is extremely useful for making the output of your queries more user-friendly or for resolving ambiguity if you're joining tables with identically named columns.

Consider **Query `Q8A`**.
The goal here might be to list employee names alongside their supervisor's names.
The `SELECT` clause reads: `SELECT E.Lname AS Employee_name, S.Lname AS Supervisor_name`.
*   Here, `E.Lname` (the last name of the employee from the table aliased as `E`) will be displayed under a column header called `Employee_name`.
*   And `S.Lname` (the last name from the table aliased as `S`, which represents the supervisor's record from the same `EMPLOYEE` table through a self-join) will be displayed under the column header `Supervisor_name`.

The `FROM` clause `FROM EMPLOYEE AS E, EMPLOYEE AS S` sets up this self-join, where `E` represents the employee and `S` represents their supervisor. The `WHERE E.Super_ssn=S.Ssn;` clause then correctly links each employee `E` to their supervisor `S` using the `Super_ssn` field.

Using `AS` to rename columns in the output doesn't change the actual column names in the database tables; it only affects how they are presented in the result set of *this particular query*.

---
<div class="page-break"></div>

## Specifying Joined Tables in the FROM Clause of SQL

So far, when we've joined tables, we've typically listed multiple tables in the `FROM` clause and then specified the join conditions in the `WHERE` clause. SQL also provides a more explicit way to specify joins directly *within* the `FROM` clause. This is often considered a more modern and sometimes clearer syntax.

*   This feature allows users to define a **`joined table`** as a single entity resulting from a join operation, right in the `FROM` clause.

Let's look at the `FROM` clause in query **`Q1A`** as an example.
The overall query is:
`SELECT Fname, Lname, Address FROM (EMPLOYEE JOIN DEPARTMENT ON Dno=Dnumber) WHERE Dname='Research';`

Focus on the `FROM` clause: `FROM (EMPLOYEE JOIN DEPARTMENT ON Dno=Dnumber)`.
*   Here, `EMPLOYEE JOIN DEPARTMENT` signifies that we are joining the `EMPLOYEE` table with the `DEPARTMENT` table.
*   The `ON Dno=Dnumber` part specifies the join condition. It's saying, "join these two tables where the `Dno` column in the `EMPLOYEE` table matches the `Dnumber` column in the `DEPARTMENT` table."
*   The result of this `(EMPLOYEE JOIN DEPARTMENT ON Dno=Dnumber)` operation is treated as a single logical table from which the `SELECT` and `WHERE` clauses then operate.
*   The `WHERE Dname='Research'` clause then filters the results of this joined table to only include rows where the department name (`Dname`) is 'Research'.

This `JOIN ... ON ...` syntax is for what's often called an **`INNER JOIN`**. An inner join, as you'll recall, only includes rows where there's a match in *both* tables based on the join condition. If an employee's `Dno` doesn't match any `Dnumber` in the `DEPARTMENT` table, that employee won't appear in the result, and vice-versa. This explicit `JOIN` syntax in the `FROM` clause helps separate join logic from filtering logic (which remains in the `WHERE` clause), often leading to more readable and maintainable queries.

---
<div class="page-break"></div>

## Different Types of JOINed Tables in SQL

When using the explicit `JOIN` syntax in the `FROM` clause, SQL allows you to **specify different types of join operations**, beyond the default inner join we just saw.

The slide highlights two main categories:
1.  **`NATURAL JOIN`**: This is a special type of join that doesn't require you to specify the join condition explicitly with an `ON` clause. Instead, it automatically joins the tables based on all columns that have the *same name and compatible data types* in both tables.
2.  Various types of **`OUTER JOIN`**: These are crucial when you want to include rows from one table even if they don't have matching rows in the other table. The common types are:
    *   **`LEFT OUTER JOIN`** (or simply `LEFT JOIN`)
    *   **`RIGHT OUTER JOIN`** (or simply `RIGHT JOIN`)
    *   **`FULL OUTER JOIN`** (or simply `FULL JOIN`)

Let's elaborate on **`NATURAL JOIN`** first, specifically when applied to two relations, say `R` and `S`.
*   As mentioned, **no explicit join condition is specified** using `ON`.
*   The database system looks for all columns in `R` that have the exact same name as columns in `S`.
*   It then implicitly creates an **`EQUIJOIN` condition** (an equality comparison) for *each such pair* of identically named attributes.
*   In the result, these common columns will appear only once, not duplicated.

`NATURAL JOIN` can be very concise if your table schemas are designed with consistent naming for joinable columns. However, it can also be a source of unexpected behavior if tables have columns with the same name that you *didn't* intend to join on, so it must be used with caution and a clear understanding of your schema.

---
<div class="page-break"></div>

## NATURAL JOIN

Let's look at an example of **`NATURAL JOIN`**, specifically query **`Q1B`** on the slide. This example also illustrates how you might need to rename attributes to make `NATURAL JOIN` work as intended if the original column names don't match perfectly.

The query is:
`SELECT Fname, Lname, Address FROM (EMPLOYEE NATURAL JOIN (DEPARTMENT AS DEPT (Dname, Dno, Mssn, Msdate))) WHERE Dname='Research';`

Let's dissect this `FROM` clause: `(EMPLOYEE NATURAL JOIN (DEPARTMENT AS DEPT (Dname, Dno, Mssn, Msdate)))`
*   First, look at the inner part: `(DEPARTMENT AS DEPT (Dname, Dno, Mssn, Msdate))`.
    *   Here, the `DEPARTMENT` table is being aliased as `DEPT`.
    *   More importantly, its columns are being explicitly renamed *within this subquery-like structure for the join*. The original columns of `DEPARTMENT` (let's assume they might be `DeptName`, `DeptNumber`, `ManagerSsn`, `MgrStartDate`) are being aliased to `Dname`, `Dno`, `Mssn`, and `Msdate` respectively *for the purpose of this join*.
*   Now, the `NATURAL JOIN` operates between the `EMPLOYEE` table and this aliased and restructured `DEPT` table.
*   The `NATURAL JOIN` will look for columns with the same name in `EMPLOYEE` and this `DEPT` view. Let's assume `EMPLOYEE` has a column named `Dno` (for department number) and our aliased `DEPT` table *also* now has a column named `Dno`.
*   Because both tables now share a column named `Dno`, the `NATURAL JOIN` will implicitly join on the condition `EMPLOYEE.Dno = DEPT.Dno`.

The slide explicitly states: "The above works with `EMPLOYEE.Dno = DEPT.Dno` as an implicit join condition." This is the core idea of `NATURAL JOIN`. If the `EMPLOYEE` table originally had, say, `DeptNo` and `DEPARTMENT` had `DNumber`, a `NATURAL JOIN` wouldn't work directly. Renaming (or ensuring consistent naming in your schema design) is key for `NATURAL JOIN` to function as expected.

The rest of the query (`SELECT Fname, Lname, Address ... WHERE Dname='Research'`) then operates on the result of this natural join, selecting employee details for those in the 'Research' department.

---
<div class="page-break"></div>

## INNER and OUTER Joins

Now, let's differentiate more formally between **`INNER JOIN`** and the various **`OUTER JOIN`** types.

*   **`INNER JOIN`** (which is the default if you just say `JOIN` or if you use the older comma-separated table list in `FROM` with conditions in `WHERE`):
    *   As we've seen, this is the default type of join when you use the `JOIN ... ON` syntax or when you simply list tables in the `FROM` clause and specify join conditions in the `WHERE` clause.
    *   The key characteristic is that a **tuple (row) is included in the result *only if a matching tuple exists in the other relation*** based on the join condition. If there's no match, the row from either table is dropped from the result.

Now for the **`OUTER JOIN`** family. These are used when you want to keep all rows from one or both tables, even if there's no match in the other.

1.  **`LEFT OUTER JOIN`** (often written as just `LEFT JOIN`):
    *   In a `LEFT OUTER JOIN`, **every tuple from the *left* table** (the table mentioned before the `LEFT JOIN` keyword) **must appear in the result**.
    *   If a row from the left table *does* have a match in the right table (based on the `ON` condition), then the columns from both tables are included, just like an inner join.
    *   However, **if a row from the left table *has no matching tuple* in the right table**, that left table row is *still included* in the result. For the columns that would have come from the right table, they are **padded with `NULL` values**.

2.  **`RIGHT OUTER JOIN`** (often written as `RIGHT JOIN`):
    *   This is the mirror image of a `LEFT OUTER JOIN`. **Every tuple from the *right* table** (the table mentioned after the `RIGHT JOIN` keyword) **must appear in the result**.
    *   If a row from the right table has a match in the left table, columns from both are included.
    *   If a row from the right table **has no matching tuple** in the left table, that right table row is still included, and the columns that would have come from the left table are **padded with `NULL` values**.

There's also `FULL OUTER JOIN`, which keeps all rows from *both* tables, padding with `NULL`s where matches don't exist on either side. Outer joins are incredibly useful when you need to see all of one entity's data, plus any related data from another entity, without losing the first entity if the related data is missing.

---
<div class="page-break"></div>

Okay, let's proceed to the next topic: Aggregate Functions in SQL.

## Aggregate Functions in SQL

**`Aggregate functions`** in SQL are powerful tools used to **summarize information from multiple tuples (rows) into a single-tuple summary**. Instead of getting back many rows of detailed data, you get one row that represents a calculation performed across a group of those rows.

SQL provides several **built-in aggregate functions**. The most common ones, as listed on the slide, are:
*   **`COUNT`**: This function counts the number of rows. It can count all rows (`COUNT(*)`) or rows where a specific column is not `NULL` (`COUNT(column_name)`).
*   **`SUM`**: This calculates the sum of values in a numeric column.
*   **`MAX`**: This finds the maximum value in a column.
*   **`MIN`**: This finds the minimum value in a column.
*   **`AVG`**: This calculates the average of values in a numeric column.

---

Often, we don't want to aggregate over the *entire* table, but rather over specific subgroups within the table. This is where **`Grouping`** comes in.
*   Grouping allows you to **create subgroups of tuples based on the values in one or more columns *before* the aggregate function is applied**. For example, you might want to find the average salary *per department*.
*   The `GROUP BY` clause is used to specify these grouping attributes.

If you want to filter these *groups* themselves (not the individual rows *before* grouping, which is what `WHERE` does), SQL provides the **`HAVING` clause**.
*   The `HAVING` clause is used **to select or reject entire groups** based on a condition that typically involves an aggregate function applied to that group. For example, show only departments where the average salary is greater than $50,000.

Finally, it's important to know where you can use these aggregate functions:
*   They can appear in the **`SELECT` clause** to display the aggregated result.
*   And, as just mentioned, they can be used in a **`HAVING` clause** to filter groups.
*   It's crucial to note that you generally *cannot* use aggregate functions directly in a `WHERE` clause. The `WHERE` clause filters rows *before* aggregation and grouping occur. If you need to filter based on an aggregated value, that's what the `HAVING` clause is for.

---
<div class="page-break"></div>

## Renaming Results of Aggregation

When you use aggregate functions in your `SELECT` clause, the database system will typically return the result under a default column name, which might be something generic like `SUM(Salary)` or system-generated. This isn't always very descriptive.

Fortunately, just as we saw with regular columns, you can **rename the columns produced by aggregate functions using the `AS` keyword**. This makes the output much more readable and user-friendly.

Let's look at the examples on the slide.
**Query `Q19`** is:
`SELECT SUM(Salary), MAX(Salary), MIN(Salary), AVG(Salary) FROM EMPLOYEE;`
This query will return a single row with four columns, containing the sum of all salaries, the maximum salary, the minimum salary, and the average salary from the `EMPLOYEE` table. The column headers might be something like `SUM(Salary)`, `MAX(Salary)`, etc.

Now, look at **Query `Q19A`**, which presents the same information but with more descriptive column names:
`SELECT SUM(Salary) AS Total_Sal, MAX(Salary) AS Highest_Sal, MIN(Salary) AS Lowest_Sal, AVG(Salary) AS Average_Sal FROM EMPLOYEE;`

In this version:
*   `SUM(Salary)` will be displayed under the column header `Total_Sal`.
*   `MAX(Salary)` will be `Highest_Sal`.
*   `MIN(Salary)` will be `Lowest_Sal`.
*   And `AVG(Salary)` will be `Average_Sal`.

This practice of aliasing aggregated columns is highly recommended for clarity, especially when these results are being consumed by applications or presented in reports. It makes the meaning of each computed value immediately obvious.

---
<div class="page-break"></div>

### Aggregate Functions in SQL (cont'd.)

An important detail regarding how aggregate functions handle data is that **`NULL` values are generally discarded or ignored when aggregate functions are applied to a particular column** (with the exception of `COUNT(*)`, which counts all rows regardless of `NULL`s in specific columns).

*   For example, if you're calculating `AVG(Salary)` and some employees have a `NULL` salary, those `NULL`s are not treated as zero, nor do they cause an error; they are simply excluded from the count of values and the sum used to calculate the average. This is usually the desired behavior – you want the average of the *known* salaries. The same applies to `SUM`, `MAX`, `MIN`. For `COUNT(column_name)`, it counts rows where `column_name` is not `NULL`.

Let's look at **Query `Q20`**: "Find the sum of the salaries of all employees of the ‘Research’ department, as well as the maximum salary, the minimum salary, and the average salary in this department."
The query uses a join in the `FROM` clause: `(EMPLOYEE JOIN DEPARTMENT ON Dno=Dnumber)`. This combines employee and department information.
The `SELECT` clause lists the aggregate functions: `SUM(Salary), MAX(Salary), MIN(Salary), AVG(Salary)`.
And the `WHERE Dname='Research';` clause filters the joined rows so that these aggregations are performed *only* for employees in the 'Research' department. Any `NULL` salaries within this 'Research' department group would be ignored by `SUM`, `MAX`, `MIN`, and `AVG`.

---

Now, for **Queries `Q21` and `Q22`**, which illustrate the `COUNT(*)` function.
`COUNT(*)` is a bit special: it counts the total number of rows that satisfy the query's conditions, irrespective of whether individual columns in those rows are `NULL`.

*   **Query `Q21`**: `SELECT COUNT(*) FROM EMPLOYEE;`
    This simply retrieves the total number of employees in the `EMPLOYEE` table.

*   **Query `Q22`**: `SELECT COUNT(*) FROM EMPLOYEE, DEPARTMENT WHERE DNO=DNUMBER AND DNAME='Research';`
    This query first effectively joins `EMPLOYEE` and `DEPARTMENT` tables based on the department number (`DNO=DNUMBER`). Then, it filters these joined rows to keep only those where the department name (`DNAME`) is 'Research'. Finally, `COUNT(*)` counts how many such combined rows exist, which gives us the number of employees in the 'Research' department.

Understanding how `NULL`s are handled and the difference between `COUNT(*)` and `COUNT(column_name)` is crucial for accurate data aggregation.

---
<div class="page-break"></div>

## Grouping: The GROUP BY Clause

We've mentioned grouping, but let's delve into the **`GROUP BY` clause** more formally. This clause is fundamental when you want to apply aggregate functions to *subsets* of rows in a table rather than the entire table.

*   The `GROUP BY` clause **partitions the relation (table) into subsets of tuples (rows)**.
*   This partitioning is **based on the values of one or more specified grouping attributes**. All rows that have the same value(s) in the grouping attribute(s) are placed into the same group.
*   Once these groups are formed, an **aggregate function can be applied to each such group independently**.

The `GROUP BY` clause itself **specifies these grouping attributes**. For example, `GROUP BY Dno` would group employees by their department number.

A common aggregate function used with `GROUP BY` is **`COUNT(*)`**, which, in this context, **counts the number of rows *within each group***. So, if you `GROUP BY Dno` and then `SELECT Dno, COUNT(*)`, you'll get each department number and the number of employees in that department.

The `GROUP BY` clause dramatically extends the power of aggregate functions, allowing for much more granular summarization of your data.

---
<div class="page-break"></div>

## Examples of GROUP BY

Let's look at some specific examples of using the `GROUP BY` clause.

A very important rule when using `GROUP BY` is that **any column listed in the `SELECT` clause must either be one of the grouping attributes OR it must be an aggregate function applied to some other attribute.** You can't select a non-aggregated, non-grouping column because it wouldn't have a single value for the group.

Consider **Query `Q24`**:
`SELECT Dno, COUNT(*), AVG(Salary) FROM EMPLOYEE GROUP BY Dno;`
*   Here, we are selecting the department number (`Dno`), the count of employees in that department (`COUNT(*)`), and the average salary for that department (`AVG(Salary)`).
*   The `FROM EMPLOYEE` clause indicates our source table.
*   The `GROUP BY Dno;` clause tells the system to first group all rows in the `EMPLOYEE` table based on their `Dno` value. All employees in department 1 will be in one group, all in department 2 in another, and so on.
*   Then, for each of these department groups, `COUNT(*)` will count the employees, and `AVG(Salary)` will calculate their average salary.
*   Notice that `Dno` is in the `SELECT` list, and it's also the grouping attribute – this is correct. `COUNT(*)` and `AVG(Salary)` are aggregate functions.

---

What happens if a **grouping attribute has `NULL` as a possible value**?
*   If the grouping attribute can be `NULL`, then a **separate group is created for all rows where that attribute is `NULL`**. So, in the example above, if some employees had a `NULL` `Dno`, they would form their own group, and `COUNT(*)` and `AVG(Salary)` would be calculated for this "unknown department" group.

---

The `GROUP BY` clause is not limited to single tables; it **may be applied to the result of a `JOIN` operation** as well.

Look at **Query `Q25`**:
`SELECT Pnumber, Pname, COUNT(*) FROM PROJECT, WORKS_ON WHERE Pnumber=Pno GROUP BY Pnumber, Pname;`
*   This query is selecting project number (`Pnumber`), project name (`Pname`), and a count.
*   The `FROM PROJECT, WORKS_ON WHERE Pnumber=Pno` part joins the `PROJECT` and `WORKS_ON` tables on the project number. This effectively gives us a list of employees working on projects (though we're not selecting employee details here, just using `WORKS_ON` for the count).
*   The `GROUP BY Pnumber, Pname;` clause then groups the results by project number *and* project name.
*   `COUNT(*)` will then count how many entries (likely representing employees or work assignments) exist for each project. The result will be a list of projects and the number of work assignments associated with each.

This illustrates how `GROUP BY` can be combined with joins to summarize data across related tables.

---
<div class="page-break"></div>

## Grouping: The GROUP BY and HAVING Clauses (cont'd.)

We've seen how `GROUP BY` forms groups, and how aggregate functions summarize data within those groups. Now, what if we want to filter these *groups themselves* based on some aggregate property? That's where the **`HAVING` clause** comes into play.

*   The **`HAVING` clause** provides a condition to **select or reject an entire group** *after* the groups have been formed by `GROUP BY` and aggregates have been computed.
*   Think of it this way: the `WHERE` clause filters individual rows *before* they are grouped. The `HAVING` clause filters *groups* of rows *after* they have been formed and aggregated.

Let's examine **Query `Q26`** on the slide. The objective is: "For each project on which *more than two employees work*, retrieve the project number, the project name, and the number of employees who work on the project."

The SQL query is laid out as follows:
We `SELECT Pnumber, Pname, COUNT(*)` – the project number, name, and a count which will represent the number of employees.
This data comes `FROM PROJECT, WORKS_ON` where these tables are joined by the condition `WHERE Pnumber=Pno`. This join links projects to the work assignments on them.
Then, we `GROUP BY Pnumber, Pname`. This ensures that the `COUNT(*)` aggregate function will count the work assignments (effectively employees) for each unique project.
Up to this point, we would have a list of all projects and the number of employees working on each.

Now, the crucial part for the filtering requirement ("more than two employees work"): the **`HAVING COUNT(*) > 2;`** clause.
*   This `HAVING` clause is applied *after* the grouping and after `COUNT(*)` has been calculated for each group (each project).
*   It checks if the `COUNT(*)` for a given project group is greater than 2.
*   Only if this condition is true for a group (i.e., only if more than two employees work on that project) will that project's `Pnumber`, `Pname`, and `COUNT(*)` be included in the final result.

So, the `HAVING` clause is essential for placing conditions on the results of aggregate functions.

---
<div class="page-break"></div>

## Combining the WHERE and the HAVING Clause

It's important to understand the distinct roles of the `WHERE` clause and the `HAVING` clause, especially when you might need to use both in a single query.

The slide presents a scenario: "we want to count the *total* number of employees whose salaries exceed $40,000 in each department, but only for departments where more than five employees work."

This task has two distinct filtering criteria:
1.  A condition on individual employee salaries (`salaries exceed $40,000`). This applies to individual rows.
2.  A condition on the department as a whole (`more than five employees work`). This applies to a group.

The slide first shows an **INCORRECT QUERY** for this task. Let's look at why it's incorrect.
The query shown is:
`SELECT Dno, COUNT(*) FROM EMPLOYEE WHERE Salary>40000 GROUP BY Dno HAVING COUNT(*) > 5;`

The issue here is a misinterpretation of "more than five employees work."
*   The `WHERE Salary>40000` correctly filters individual employees *before* grouping, so only employees earning more than $40,000 are considered.
*   Then, `GROUP BY Dno` groups these *already filtered* employees by department.
*   The `HAVING COUNT(*) > 5` then checks if the count of *these filtered employees* (those earning > $40k) is greater than 5.

This query would answer: "For which departments are there more than five employees who `*each earn more than $40,000*` ?" This is *not* the original question, which was about departments having more than five employees *in total*, and *then* for those departments, counting how many employees make over $40,000.

The order and application of `WHERE` and `HAVING` are critical for achieving the correct logic.

---
<div class="page-break"></div>

### Combining the WHERE and the HAVING Clause (continued)

Now, let's look at the **Correct Specification of the Query** for the problem: "For each department that has more than five employees, retrieve the department number and the number of its employees who are making more than $40,000."

The key principle, as the slide notes, is: **the `WHERE` clause applies tuple by tuple (row by row) *before* grouping, whereas `HAVING` applies to an entire group of tuples *after* grouping.**

The **Query `Q28`** provided on the slide aims to implement this correct logic. Let's analyze its structure:
The main `SELECT` statement is `SELECT Dnumber, COUNT(*)`. We want the department number and a count.
The `FROM DEPARTMENT, EMPLOYEE` indicates we're working with these two tables.
The `WHERE` clause has several parts:
*   `Dnumber=Dno`: This is the join condition between `DEPARTMENT` and `EMPLOYEE`.
*   `AND Salary>40000`: This is crucial. It filters individual employee records *before* any grouping occurs. So, the `COUNT(*)` in the `SELECT` clause will only be counting employees who meet this salary criterion.
*   `AND Dno IN (SELECT Dno FROM EMPLOYEE GROUP BY Dno HAVING COUNT(*) > 5)`: This is a subquery used to identify the departments we're interested in.
    *   The subquery `(SELECT Dno FROM EMPLOYEE GROUP BY Dno HAVING COUNT(*) > 5)` itself first groups *all* employees by their department number (`Dno`).
    *   Then, its `HAVING COUNT(*) > 5` clause filters these groups, so the subquery *only returns the `Dno` values for departments that have more than five employees in total*.
    *   The outer `WHERE` clause then uses `Dno IN (...)` to ensure that we are only considering employees (who also meet the salary condition) if they belong to one of these departments (those with more than 5 total employees).

Finally, the `GROUP BY Dnumber` in the outer query groups the already filtered employees (high salary, in a large department) by their department number so that `COUNT(*)` can give us the count of such employees *per department*.

This query structure correctly separates the condition on total department size (handled by the subquery with `HAVING`) from the condition on individual employee salary (handled by the outer query's `WHERE` clause), and then performs the final aggregation. This demonstrates a more complex interplay of `WHERE`, `GROUP BY`, `HAVING`, and subqueries.

---
<div class="page-break"></div>

## Use of CASE

SQL also includes a **`CASE` construct**, which is very useful for implementing conditional logic directly within your SQL statements. Think of it as an IF-THEN-ELSE type of structure that can be used to determine a value.

*   The `CASE` construct is **used when a value can be different based on certain conditions.**
*   It's quite versatile: it **can be used in any part of an SQL query where a value is expected**. This means you can use it in the `SELECT` list, in the `WHERE` clause, in the `SET` clause of an `UPDATE` statement, or even within an `ORDER BY` clause.
*   Consequently, it's **applicable when querying, inserting, or updating tuples**.

The `CASE` statement evaluates conditions in order and returns a value when the first condition is met. If no conditions are met and there's no `ELSE` part, it typically returns `NULL`.

---
<div class="page-break"></div>

## EXAMPLE of use of CASE

Let's look at an example of the `CASE` construct in action, specifically within an `UPDATE` statement. This will illustrate how we can apply conditional logic to modify data.
The scenario, as stated, is that "employees are receiving different raises in different departments." This is presented as a variation of an update operation, labeled `U6'` on your slides.

The core of the SQL statement you see is an `UPDATE EMPLOYEE` command. We're targeting the `EMPLOYEE` table, and specifically, we intend to `SET` a new value for the `Salary` column.

The really interesting part is *how* this new salary is determined. Instead of a single calculation, the new salary depends on the employee's department. This is where the `CASE` expression comes into play.

If you look at the `CASE` structure within the `SET Salary = ...` part:
*   The first condition checks `WHEN Dno = 5`. If an employee is in department number 5, then their new salary is calculated as their current `Salary + 2000`.
*   If they are not in department 5, the `CASE` expression moves to the next condition: `WHEN Dno = 4`. If they are in department 4, their new salary becomes their current `Salary + 1500`.
*   And if they are in neither department 5 nor 4, it checks `WHEN Dno = 1`. For employees in department 1, the new salary is their current `Salary + 3000`.

Now, a crucial point about `CASE` statements in `UPDATE`s: As written on the slide, if an employee is *not* in department 1, 4, or 5, and if there's no `ELSE` clause in this `CASE` expression, their salary would typically be updated to `NULL`. This is often not the desired outcome.

To handle this, one would usually do one of two things:
1.  Add an `ELSE Salary` clause within the `CASE` expression. This means if none of the specified `WHEN` conditions are met, the salary remains unchanged (it's set back to its current value).
2.  Alternatively, add a `WHERE Dno IN (1, 4, 5)` clause to the `UPDATE` statement itself, so the `UPDATE` operation and the `CASE` logic only apply to employees in those specific departments.

The example on the slide effectively demonstrates the conditional assignment based on `Dno`, showing the core power of `CASE` to handle varied logic within a single SQL statement.

---
<div class="page-break"></div>

## EXPANDED Block Structure of SQL Queries

This slide provides a nice summary of the **EXPANDED Block Structure of SQL `SELECT` Queries**, showing the typical order of clauses. Understanding this order is crucial because it also generally reflects the conceptual order of operations.

The structure is:
1.  **`SELECT <attribute and function list>`**: This is where you specify what data you want to see in your results – the columns from your tables, or values computed by functions (like aggregate functions or other calculations).
2.  **`FROM <table list>`**: This clause identifies the source tables your data will come from. If you're getting data from multiple tables, this is also where you'd typically specify your joins (either using the older comma-separated syntax with conditions in the `WHERE` clause, or the more modern `JOIN ... ON` syntax).
3.  **`[ WHERE <condition> ]`**: This is an optional clause that filters individual rows from the source tables based on specified conditions. It's applied *before* any grouping takes place.
4.  **`[ GROUP BY <grouping attribute(s)> ]`**: Also optional, this clause is used to group rows that have the same values in one or more specified columns. This is essential if you're using aggregate functions and want to apply them to subgroups of your data.
5.  **`[ HAVING <group condition> ]`**: This optional clause is used to filter the *groups* created by the `GROUP BY` clause. The conditions in `HAVING` typically involve aggregate functions. It's applied *after* grouping. You'd only use `HAVING` if you've used `GROUP BY`.
6.  **`[ ORDER BY <attribute list> ];`**: Finally, this optional clause sorts the rows in the final result set based on the values in one or more columns, either in ascending (ASC, the default) or descending (DESC) order.

While this is the order in which you *write* the clauses in an SQL query, it's helpful to remember that the database doesn't necessarily execute them in exactly this sequence. Conceptually, operations like `FROM` and `WHERE` happen early, followed by `GROUP BY` and `HAVING`, then the `SELECT` projection, and `ORDER BY` is usually the very last step applied to the fully formed result set. Knowing the written order is key for syntax, and understanding the conceptual execution helps in designing effective queries.

---
<div class="page-break"></div>

## Specifying Constraints as Assertions and Actions as Triggers

Now we shift gears a bit to discuss how SQL allows us to specify more complex **Semantic Constraints** and define **Actions as Triggers**. These mechanisms go beyond the basic integrity constraints (like primary keys, foreign keys, `NOT NULL`, `UNIQUE`, `CHECK` on a column) that are often tied directly to table definitions.

The slide points out that some semantic constraints are beyond the scope of what can be directly expressed in the EER (Enhanced Entity-Relationship) model or basic relational model constraints. For these more complex business rules, SQL provides:

1.  **`CREATE ASSERTION`**:
    *   This statement allows you to specify additional types of constraints that might involve multiple tables or more complex conditions than a simple `CHECK` constraint on a single table or column.
    *   Essentially, an assertion defines a condition that the database state must always satisfy. If any data modification (insert, update, delete) would cause the assertion's condition to become false, the modification is typically rejected.

2.  **`CREATE TRIGGER`**:
    *   A trigger is a more procedural mechanism. It allows you to **specify automatic actions that the database system will perform when certain events occur and/or certain conditions are met**.
    *   Think of triggers as "event-condition-action" rules. When a defined event (like an `INSERT` on a table, an `UPDATE` of a specific column, or a `DELETE`) happens, if an associated condition is true, then a specified action (a block of SQL code) is automatically executed.

These are powerful features for maintaining complex data integrity rules and automating database behavior.

---
<div class="page-break"></div>

## Specifying General Constraints as Assertions in SQL

Let's focus on **`CREATE ASSERTION`**. This is how SQL allows us to define general constraints that span across the database, often involving multiple tables or complex conditions that aren't easily tied to a single column or table's `CHECK` constraint.

*   When you use `CREATE ASSERTION`, you essentially **specify a query that selects any tuples (or combinations of tuples) that *violate* the desired condition**. The assertion then typically states that this query should *always return an empty set*.
*   The slide correctly notes that you should **use assertions only in cases where the constraint goes beyond a simple `CHECK` constraint**. `CHECK` constraints are usually defined at the column or table level and apply to individual rows or attributes within a single table. Assertions are for broader, database-wide rules.

A classic example given is: "**Salary of an employee must be less than the manager.**"
This rule involves comparing data from potentially two different employee records (the employee and their manager) and possibly involves the `DEPARTMENT` table to find out who the manager is. This is too complex for a simple `CHECK` constraint on the `EMPLOYEE` table's `Salary` column.

The example SQL for this assertion is:
`CREATE ASSERTION SALARY_CONSTRAINT CHECK (NOT EXISTS (...));`
The core of the assertion is the `CHECK` clause, which contains a condition that must always be true. Here, it's `NOT EXISTS` followed by a subquery.

Let's look at that subquery:
` (SELECT * FROM EMPLOYEE E, EMPLOYEE M, DEPARTMENT D WHERE E.Salary > M.Salary AND E.Dno = D.Dnumber AND D.Mgr_ssn = M.Ssn)`
*   This subquery is designed to find any situation that *violates* our rule.
*   It joins `EMPLOYEE E` (representing the employee) with `EMPLOYEE M` (representing the manager) and `DEPARTMENT D`.
*   The conditions are:
    *   `E.Salary > M.Salary`: This looks for an employee `E` whose salary is greater than their manager `M`'s salary (the violation).
    *   `E.Dno = D.Dnumber`: Links the employee to their department.
    *   `D.Mgr_ssn = M.Ssn`: Links the department to its manager `M`.
*   If this subquery finds *any* such combination of an employee earning more than their direct manager, it will return rows.

The `NOT EXISTS` in the `CHECK` clause means the assertion `SALARY_CONSTRAINT` is satisfied only if this subquery returns *no rows*. If an operation (like an `INSERT` or `UPDATE`) would cause this subquery to return a row (i.e., create a violation), the operation would be disallowed to maintain the assertion.

---
<div class="page-break"></div>

## Introduction to Triggers in SQL

Now let's turn to **`Triggers`**. Triggers are a more active way to enforce business rules or automate actions in response to database events.

*   The **`CREATE TRIGGER` statement** is used to define these triggers.
*   They are primarily **used to monitor the database** for specific events.

A **typical trigger has three main components**, which make it a rule for what's sometimes called an "active database" (a database that can react to events automatically):
1.  **`Event(s)`**: This specifies *what* database operation will cause the trigger to be considered for firing. Common events are `INSERT`, `UPDATE` (often on specific columns), or `DELETE` on a particular table. You can also specify if the trigger should fire `BEFORE` or `AFTER` the event.
2.  **`Condition`**: This is an optional logical expression. If a condition is specified, the trigger's action will only execute if the event occurs *and* this condition evaluates to `TRUE`.
3.  **`Action`**: This defines *what* the trigger does when it fires (i.e., when the event occurs and the condition, if any, is met). The action is typically a block of SQL statements, which could perform further data modifications, raise errors, call stored procedures, etc.

Triggers are very powerful for tasks like maintaining audit trails, enforcing complex referential integrity that goes beyond foreign keys, or propagating changes to other tables automatically.

---
<div class="page-break"></div>

## USE OF TRIGGERS

Let's look at an example of a trigger to see these components in action. The slide notes that this example uses a standard syntax, but specific SQL implementations (like PostgreSQL, MySQL, Oracle, SQL Server) might have variations in their `CREATE TRIGGER` syntax.

The example trigger, named `R5`, is `CREATE TRIGGER SALARY_VIOLATION ...`.
Its purpose seems to be to prevent an employee's salary from being set higher than their supervisor's salary.

Let's break down its definition as shown on the slide:
*   **Event**: `BEFORE INSERT OR UPDATE OF Salary, Supervisor_ssn ON EMPLOYEE`
    *   This trigger is set to fire `BEFORE` an `INSERT` operation on the `EMPLOYEE` table, or `BEFORE` an `UPDATE` operation that affects either the `Salary` column or the `Supervisor_ssn` column of the `EMPLOYEE` table.
*   **Granularity**: `FOR EACH ROW`
    *   This specifies that the trigger logic should be executed for each individual row affected by the `INSERT` or `UPDATE` statement. (The alternative is `FOR EACH STATEMENT`, which is less common for this type of validation).
*   **Condition**: `WHEN (NEW.SALARY > (SELECT Salary FROM EMPLOYEE WHERE Ssn = NEW.Supervisor_Ssn))`
    *   This is the conditional part. `NEW` is a special keyword in triggers that refers to the new row data (for an `INSERT`) or the row data as it would be *after* the `UPDATE`.
    *   So, `NEW.SALARY` is the proposed new salary for the employee.
    *   `NEW.Supervisor_Ssn` is the SSN of this employee's supervisor (from the row being inserted or updated).
    *   The subquery `(SELECT Salary FROM EMPLOYEE WHERE Ssn = NEW.Supervisor_Ssn)` fetches the salary of that supervisor.
    *   The condition checks if the employee's proposed new salary (`NEW.SALARY`) is greater than their supervisor's salary. If it is, the condition is true, and the trigger's action will execute.
*   **Action**: `INFORM_SUPERVISOR (NEW.Supervisor.Ssn, NEW.Ssn)`
    *   *(Professor's note: As per the slide, `INFORM_SUPERVISOR` is a placeholder for the action. In a real system, this might be a call to a stored procedure, or it might be an action to `SIGNAL` an error and prevent the update. The syntax `NEW.Supervisor.Ssn` also seems like a slight typo; it would more likely be `NEW.Supervisor_Ssn` to refer to the supervisor's SSN from the new/updated row itself, and `NEW.Ssn` for the employee's own SSN.)*
    *   Assuming `INFORM_SUPERVISOR` is a conceptual action, it would be invoked if the salary violation condition is met. In a practical scenario, if the goal is to *prevent* the update, the action would typically raise an error, which would then cause the original `INSERT` or `UPDATE` operation to fail.

This trigger demonstrates how events, conditions, and actions come together to enforce a business rule automatically.

---
<div class="page-break"></div>

## Views (Virtual Tables) in SQL

Next, let's discuss **`Views`** in SQL. Views are a very important concept for data abstraction, security, and simplifying complex queries.

*   The **concept of a view in SQL** is that it's like a **virtual table**.
*   A view is a **single table that is derived from other tables**, which are called the **defining tables** or base tables.
*   It's considered **virtual** because, in most cases, the view itself **does not store data directly**. Instead, the definition of the view (which is essentially a stored SQL query) is stored in the database.
*   When you query a view, the database system typically executes the view's underlying query against the base tables and presents the result *as if* it were a real table. So, it's not necessarily "populated" in the sense of having its own persistent storage distinct from the base tables (though some systems support "materialized views" which do store data, but that's a more advanced topic).

Views provide a way to look at the data in a different structure or with certain rows/columns filtered out, without altering the underlying base tables.

---
<div class="page-break"></div>

## Specification of Views in SQL

To define a view, we use the **`CREATE VIEW` command**.

*   When you create a view, you need to **give the view a name**, you can optionally provide a **list of attribute names for the view's columns**, and most importantly, you provide a **query that specifies the contents of the view**. This query is what defines how the view is derived from the base tables.

The slide shows two examples, `V1` and `V2`, illustrating different ways to specify views.

Let's look at **`V1`**:
`CREATE VIEW WORKS_ON1 AS SELECT Fname, Lname, Pname, Hours FROM EMPLOYEE, PROJECT, WORKS_ON WHERE Ssn=Essn AND Pno=Pnumber;`
*   Here, a view named `WORKS_ON1` is being created.
*   No explicit column names are given for the view itself in the `CREATE VIEW` line, so the view's columns will **inherit the names from the `SELECT` list** of the defining query: `Fname`, `Lname`, `Pname`, and `Hours`.
*   The `AS SELECT ...` part is the defining query. It joins the `EMPLOYEE`, `PROJECT`, and `WORKS_ON` tables to retrieve the first name and last name of employees, the name of the project they work on, and the hours they've worked on that project.
*   So, `WORKS_ON1` will act like a table that directly presents this combined information.

Now, consider **`V2`**:
`CREATE VIEW DEPT_INFO(Dept_name, No_of_emps, Total_sal) AS SELECT Dname, COUNT(*), SUM(Salary) FROM DEPARTMENT, EMPLOYEE WHERE Dnumber=Dno GROUP BY Dname;`
*   In this case, the view is named `DEPT_INFO`, and **explicit column names for the view are provided in parentheses right after the view name**: `(Dept_name, No_of_emps, Total_sal)`.
*   The defining query selects `Dname` (department name), `COUNT(*)` (which will be the number of employees), and `SUM(Salary)` (the total salary for the department). It joins `DEPARTMENT` and `EMPLOYEE`, groups the results by `Dname`, and then calculates the aggregates.
*   The results of `Dname`, `COUNT(*)`, and `SUM(Salary)` from the query will be mapped to the view columns `Dept_name`, `No_of_emps`, and `Total_sal` respectively. This is particularly useful when the defining query involves aggregate functions or expressions, as their default names might not be very descriptive.

So, `CREATE VIEW` allows you to encapsulate complex queries and present their results as simple, virtual tables.

---
<div class="page-break"></div>

### Specification of Views in SQL (cont'd.)

Once a view is defined, it behaves much like a regular table in many contexts.

*   A key benefit is that **once a View is defined, SQL queries can use the View relation in their `FROM` clause** just as if it were a base table. This can greatly simplify queries that would otherwise need to repeatedly include the complex logic now encapsulated in the view definition.
    *   For example, you could now write `SELECT * FROM WORKS_ON1 WHERE Lname = 'Smith';` without having to rewrite the join between `EMPLOYEE`, `PROJECT`, and `WORKS_ON`.

*   An important characteristic of standard (non-materialized) views is that the **view is always up-to-date**.
    *   This is because the view itself doesn't store data. When you query a view, its defining query is executed against the current state of the base tables. So, any changes to the base tables are immediately reflected when you query the view.
    *   This is the **responsibility of the DBMS and not the user**. The user doesn't need to do anything to "refresh" a standard view.

*   Finally, if a view is no longer needed, you can remove it from the database using the **`DROP VIEW` command**.
    *   The syntax is simple: `DROP VIEW view_name;`.
    *   This **disposes of the view definition**. It does *not* affect the data in the underlying base tables from which the view was derived.

Views are a cornerstone of database design for simplifying access, providing logical data independence, and implementing security by restricting access to only certain data through the view.

---
<div class="page-break"></div>

## Schema Change Statements in SQL

Databases are not static; their structure often needs to evolve over time as requirements change. SQL provides **Schema evolution commands** to manage these changes.

*   A **DBA (Database Administrator) may want to change the schema while the database is operational**. For example, they might need to add a new column to a table, remove an existing one, or change a constraint.
*   A significant advantage of these SQL schema change statements (like `ALTER TABLE`) is that they often **do not require a full recompilation of the entire database schema** or a lengthy downtime. The DBMS handles the modifications, often allowing ongoing operations to continue, though there might be brief locking or performance implications during the change.

These commands provide the flexibility needed to adapt the database structure to new business needs without necessarily rebuilding the entire database from scratch. The primary command for modifying existing table structures is `ALTER TABLE`.

---
<div class="page-break"></div>

## The DROP Command

While `ALTER` is for modifying, the **`DROP` command** in SQL is used for removing schema elements entirely.

*   The `DROP` command can be used to **drop various named schema elements**, such as:
    *   Entire tables (`DROP TABLE table_name;`)
    *   Domains (`DROP DOMAIN domain_name;`) – if your database supports user-defined domains.
    *   Constraints (`ALTER TABLE table_name DROP CONSTRAINT constraint_name;` – though `DROP CONSTRAINT` is part of `ALTER TABLE`, the concept of dropping is relevant here).
    *   Entire schemas (`DROP SCHEMA schema_name;`)

When dropping schema elements, especially those that might be referenced by other elements (like a table referenced by views or foreign keys), SQL provides **drop behavior options**:
*   **`CASCADE`**: If you specify `CASCADE`, the DBMS will not only drop the named element but also automatically drop any *other* schema elements that depend on it. For example, if you `DROP TABLE ... CASCADE;`, any views defined on that table, or foreign key constraints referencing that table, would also be dropped. This is powerful but must be used with extreme caution, as it can lead to widespread, unintended deletions.
*   **`RESTRICT`**: If you specify `RESTRICT` (or if it's the default behavior and you don't specify `CASCADE`), the `DROP` operation will fail if the element you're trying to drop is referenced by other schema elements. For example, you cannot `DROP TABLE ... RESTRICT;` if there are views or foreign keys that depend on that table. You would have to drop those dependent objects first.

The slide gives an example: **`DROP SCHEMA COMPANY CASCADE;`**
*   This command would attempt to remove the entire schema named `COMPANY`.
*   Because `CASCADE` is specified, it will also remove **all elements within that schema**, including all its tables, views, constraints, assertions, triggers, etc. This is a very destructive command if used improperly.

The slide also mentions that **`RESTRICT` drops "only nothing in it"**. This is a slightly informal way of saying that `RESTRICT` will only succeed if the object being dropped has no dependent objects or, in the case of a schema, if the schema is empty.

---
<div class="page-break"></div>

## The ALTER table command

The primary command for modifying the structure of an existing table is the **`ALTER TABLE` command**. This is a very versatile command that allows for a variety of changes.

**`Alter table` actions include**:
*   **Adding or dropping a column (attribute)**: You can add new columns to a table or remove existing ones.
    *   When adding a column, you specify its name and data type, and optionally a default value or constraints.
    *   When dropping a column, any data in that column is lost.
*   **Changing a column definition**: You might be able to change a column's data type (though there are restrictions, e.g., you can't always change from character to numeric if existing data is incompatible), change its default value, or modify its nullability.
*   **Adding or dropping table constraints**: You can add new constraints (like `PRIMARY KEY`, `FOREIGN KEY`, `UNIQUE`, `CHECK`) to a table after it has been created, or you can remove existing constraints.

The slide provides a simple example of adding a column:
**`ALTER TABLE COMPANY.EMPLOYEE ADD COLUMN Job VARCHAR(12);`**
*   This statement modifies the `EMPLOYEE` table within the `COMPANY` schema.
*   `ADD COLUMN Job VARCHAR(12)` specifies that a new column named `Job` is being added.
*   The data type for this new `Job` column will be `VARCHAR(12)`, meaning it can store variable-length character strings up to 12 characters.
*   When this command is executed, existing rows in the `EMPLOYEE` table will have this new `Job` column added, and its value for these existing rows will typically be `NULL` by default, unless a `DEFAULT` value was also specified in the `ADD COLUMN` clause.

`ALTER TABLE` is a fundamental tool for database evolution.

---
<div class="page-break"></div>

## Adding and Dropping Constraints

As mentioned, the `ALTER TABLE` command is also used to **change constraints specified on a table**. This typically means adding new constraints or dropping existing ones.

*   You can **add or drop a named constraint**. It's good practice to name your constraints when you create them (either during `CREATE TABLE` or when adding them later with `ALTER TABLE`) because it makes them easier to manage, especially if you need to drop or modify them later.

The slide shows an example of dropping a constraint:
**`ALTER TABLE COMPANY.EMPLOYEE DROP CONSTRAINT EMPSUPERFK CASCADE;`**
*   This statement targets the `EMPLOYEE` table in the `COMPANY` schema.
*   `DROP CONSTRAINT EMPSUPERFK` indicates that an existing constraint named `EMPSUPERFK` is to be removed. This name suggests it was likely a foreign key constraint related to an employee's supervisor (perhaps `EMP`loyee `SUPER`visor `F`oreign `K`ey).
*   The `CASCADE` option here means that if dropping this foreign key constraint would affect other dependent objects (though less common for dropping a constraint itself compared to dropping a table), those effects should be cascaded. More typically for `DROP CONSTRAINT`, `CASCADE` might be relevant if other constraints or database features depend on this specific constraint's existence, or it might influence how related indexes are handled by some database systems. For a simple foreign key, often `CASCADE` or `RESTRICT` (if it's the default) would behave similarly unless other objects specifically reference this constraint by name in a dependent way. The primary effect is the removal of the `EMPSUPERFK` constraint itself.

Being able to add and drop constraints after table creation is vital for refining data integrity rules as the application and database evolve.

---
<div class="page-break"></div>

## Dropping Columns, Default Values

Let's look more specifically at **dropping columns** and managing **default values** using `ALTER TABLE`.

*   **To drop a column** from a table, you use `ALTER TABLE ... DROP COLUMN ...`.
    *   When dropping a column, you often have to specify a behavior if that column is referenced elsewhere (e.g., in views, indexes, or constraints). The options are typically:
        *   **`CASCADE`**: If `CASCADE` is specified, the column will be dropped, and any views, indexes, constraints, or other schema objects that depend on this column will also be automatically dropped or appropriately altered. This is powerful but can have far-reaching consequences.
        *   **`RESTRICT`**: If `RESTRICT` is specified (or is the default), the `DROP COLUMN` operation will fail if the column is referenced by any other views, constraints, etc. You would need to remove those dependencies manually before you could drop the column with `RESTRICT`.
    *   The example given is: **`ALTER TABLE COMPANY.EMPLOYEE DROP COLUMN Address CASCADE;`**
        This command removes the `Address` column from the `COMPANY.EMPLOYEE` table. Because `CASCADE` is used, if any views selected this `Address` column, or if any check constraints specifically referenced it, those dependent objects would also be handled (e.g., views might become invalid or have the column removed from their definition, constraints might be dropped).

---

*   **Default values for columns can also be dropped or altered** after a table is created.
    *   To drop an existing default value for a column, the syntax is typically:
        **`ALTER TABLE COMPANY.DEPARTMENT ALTER COLUMN Mgr_ssn DROP DEFAULT;`**
        This command modifies the `Mgr_ssn` column in the `COMPANY.DEPARTMENT` table by removing its current default value. After this, if a new row is inserted into `DEPARTMENT` without specifying a value for `Mgr_ssn`, and if `Mgr_ssn` allows `NULL`s, it will be `NULL`. If it doesn't allow `NULL`s and has no default, an insert without providing a value would fail.

    *   To set a new default value (or change an existing one):
        **`ALTER TABLE COMPANY.DEPARTMENT ALTER COLUMN Mgr_ssn SET DEFAULT '333445555';`**

        This command sets the default value for the `Mgr_ssn` column in the `COMPANY.DEPARTMENT` table to '333445555'. Now, if a new row is inserted without a value for `Mgr_ssn`, this default value will be automatically used.

These `ALTER TABLE` capabilities for columns and defaults are essential for adapting your table structures as your application's data requirements evolve.

---
<div class="page-break"></div>

## Table 7.2 Summary of SQL Syntax

Alright class, this slide, and the one that follows, present **Table 7.2**. This table provides a very useful **Summary of SQL Syntax** for many of the commands we've been discussing. Think of it as a quick reference guide.

Now, I won't read every single line of syntax to you – you can see the precise structure on the slide. Instead, I'll highlight the categories of commands and explain what the different parts of the syntax represent in plain language.

*   First, we have **`CREATE TABLE`**. The syntax shows you how to define a new table. You'd provide a name for the table, and then within parentheses, you list each column. For each column, you specify its name, its data type (like `INTEGER`, `VARCHAR`, and so on), and then any optional constraints that apply directly to that attribute, such as `NOT NULL` or a `UNIQUE` constraint. After defining all the columns, you can also add table-level constraints, like a `PRIMARY KEY` that spans multiple columns, or `FOREIGN KEY` constraints.

*   Next is **`DROP TABLE`**. This is straightforward: you use `DROP TABLE` followed by the name of the table you wish to remove.

*   Then there's **`ALTER TABLE`** with the **`ADD`** option. This is used to add a new column to an existing table. You'd specify the table name, use the `ADD` keyword, then give the new column's name and its data type.

*   The **`SELECT` statement** structure is quite detailed here, as it's the workhorse for querying data.
    *   It begins with `SELECT`, optionally followed by the `DISTINCT` keyword if you want to eliminate duplicate rows from your result. Then you list what you want to retrieve – this could be specific column names, a star or asterisk to indicate all columns, or functions that compute values.
    *   The `FROM` clause comes next, where you specify the table or tables you're querying. The syntax shown here also indicates that you can use aliases for your table names, which is good practice, and it points to the modern syntax for joined tables, like `EMPLOYEE JOIN DEPARTMENT ON ...`.
    *   Optionally, you can have a `WHERE` clause to filter rows based on a condition.
    *   Then, also optionally, a `GROUP BY` clause where you list the attributes you want to group by. This is typically used with aggregate functions.
    *   If you have a `GROUP BY` clause, you can also have an optional `HAVING` clause to filter the groups themselves based on a condition (often involving an aggregate function).
    *   And finally, an optional `ORDER BY` clause where you list the columns that will determine the sort order of your final results, specifying `ASC` for ascending or `DESC` for descending.
    *   The slide further clarifies that the list of attributes you select can be an asterisk for all columns, or a series of individual column names, or functions. When using functions, you can also apply them to distinct values of a column or to all values (represented by an asterisk within the function, like `COUNT(*)`).
    *   The grouping attributes in the `GROUP BY` clause are simply one or more column names.
    *   And the order specification in `ORDER BY` is either `ASC` or `DESC`.

*   Lastly on this slide, we have **`INSERT INTO`**. This command is for adding new rows. You specify the table name, and optionally, a list of column names if you're only providing values for some columns or want to specify a different order. Then, you either use the `VALUES` keyword followed by a list of the actual data values for the new row (or rows), or you can use a complete `SELECT` statement to populate the new rows from the result of another query.

This first part of Table 7.2 covers the essential commands for defining tables and for querying and inserting data. The next slide will continue with more commands.

---
<div class="page-break"></div>

## Table 7.2 (continued) Summary of SQL Syntax

We're continuing with **Table 7.2, the Summary of SQL Syntax**.

Let's pick up with the `DELETE` command:
*   The syntax is **`DELETE FROM`** followed by the table name. After that, there's an optional **`WHERE` clause** where you specify a condition. This condition determines which rows will be deleted. It's incredibly important to remember that if you omit the `WHERE` clause, the `DELETE` statement will remove *all rows* from the table. So, always be very careful and ensure your `WHERE` clause is correct if you only intend to delete specific rows.

*   Next is the **`UPDATE`** command, used for modifying existing data.
    *   You start with **`UPDATE`** and the table name.
    *   Then, the **`SET` clause** is where you specify the changes. You'll have one or more assignments, where a column name is set equal to a new value or an expression that calculates the new value. If you're updating multiple columns, you separate these assignments with commas.
    *   Similar to `DELETE`, there's an optional **`WHERE` clause**. This clause identifies which rows in the table should be updated. If you leave out the `WHERE` clause, the `UPDATE` statement will apply the changes specified in the `SET` clause to *all rows* in the table.

*   Then we have the syntax for **`CREATE INDEX`**.
    *   You can optionally specify **`UNIQUE`** if the index should enforce that all values in the indexed column (or combination of columns) are unique.
    *   You provide a name for the index, then use the **`ON` keyword** followed by the table name.
    *   In parentheses, you list the column or columns that the index will be built on. For each column, you can optionally specify an order, `ASC` for ascending or `DESC` for descending, which is particularly relevant for multi-column indexes.
    *   The **`CLUSTER`** keyword is also shown as an option. This is a feature in some database systems where the table's physical data storage on disk is ordered according to this clustered index. A table can typically have only one clustered index.

*   To remove an index, the command is **`DROP INDEX`**, followed by the index name.

*   We also see the syntax for **`CREATE VIEW`**.
    *   You give the view a name. Optionally, in parentheses, you can list the column names for the view. If you don't, the view's columns will take their names from the `SELECT` statement that defines the view.
    *   The **`AS` keyword** is followed by the actual `SELECT` statement whose result will form the virtual table represented by the view.

*   And to remove a view, it's **`DROP VIEW`**, followed by the view's name.

Finally, the slide includes a very important **NOTE**: "The commands for creating and dropping indexes are not part of standard SQL."
What this means is that while the *concept* of indexes is universal in relational databases for performance, and most systems have commands like `CREATE INDEX` and `DROP INDEX`, the precise syntax and the advanced options available (like `CLUSTER` or specific index types) can differ from one database system to another (for example, between Oracle, SQL Server, MySQL, and PostgreSQL). So, for index management, you'd always want to consult the documentation specific to the database system you are using.

This summary table, as a whole, is a great resource for a quick reminder of how these common SQL commands are structured.

---
<div class="page-break"></div>

## Summary

So, let's briefly recap the main themes and capabilities we've explored in this chapter, which focused on "More SQL."

*   We significantly expanded our understanding of **Complex SQL** queries. This included:
    *   Learning about **`Nested queries`**, or subqueries, and how they can be used for sophisticated data filtering and comparisons.
    *   Looking at the modern syntax for specifying **`Joined tables`** directly within the `FROM` clause, including `NATURAL JOIN`.
    *   Understanding the importance and usage of **`Outer joins`** – `LEFT`, `RIGHT`, and by extension `FULL` – for scenarios where you need to preserve rows even if there are no matches in a related table.
    *   Revisiting and applying **`Aggregate functions`** like `COUNT`, `SUM`, `MAX`, `MIN`, and `AVG` to perform calculations across sets of rows.
    *   And mastering **`Grouping`** with the `GROUP BY` clause, often in conjunction with the `HAVING` clause, to apply these aggregate functions to specific subgroups of our data.

*   We then moved on to discuss how SQL allows us to handle more advanced **semantic constraints**:
    *   Through **`CREATE ASSERTION`**, which lets us define broad, database-wide integrity rules that must always hold true, often spanning multiple tables or complex conditions.
    *   And with **`CREATE TRIGGER`**, which enables us to define automatic actions that the database will perform in response to specific events like inserts, updates, or deletes, thus creating a more "active" database that can enforce complex business logic.

*   We also explored **`Views`**, learning how the **`CREATE VIEW` statement** allows us to define virtual tables. These views simplify complex query logic, enhance data security by restricting access, and provide a level of logical data independence. We briefly acknowledged that there are different strategies for how views are handled by the DBMS, including the concept of materialization in more advanced systems.

*   Finally, we looked at **Schema Modification**, which is a key responsibility for Database Administrators. The primary tool here is the **`ALTER TABLE`** command, which provides the flexibility to:
    *   **`ADD` and `DROP COLUMN`s**, changing the attributes of a table as business needs evolve.
    *   And manage constraints, such as adding new ones or dropping existing ones using options within `ALTER TABLE`, to refine the integrity rules of the database over time.

This chapter has equipped you with a much richer set of SQL tools. You can now write more sophisticated queries, enforce more complex business rules, and manage the structure of your databases more effectively. These are all critical skills for anyone working seriously with database systems.

---
<div class="page-break"></div>